---
title: "Effect of Weighting Poll Data to 2014 Indyref Vote on Reported Pro-independence Voting Intention"
author: "Mark McGeoghegan"
date: "Wednesday 21 December 2022"
header-includes:
  - \usepackage{dcolumn}
  - \usepackage{titling}
  - \pretitle{\begin{flushleft}\LARGE}
  - \posttitle{\end{flushleft}}
  - \preauthor{\begin{flushleft}}
  - \postauthor{\end{flushleft}}
  - \predate{\begin{flushleft}}
  - \postdate{\end{flushleft}}
output:
  pdf_document:
  toc: TRUE
  toc_depth: 4
  number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.width = 10)
```

```{css}
body, h1, h2, h3, h4{
font-family: "Times New Roman", Times, serif;
}
```

```{r, results='hide', message=FALSE, warning=FALSE}
setwd("C:/Users/markm/Desktop/2014WeightingEffect/2014WeightEffect")
getwd()
library(tinytex)
library(tidyverse)
library(expss)
library(lmtest)
library(sandwich)
library(extrafont)
library(showtext)
library(ggplot2)
library(ggthemes)
library(lmtest)
library(descr)
library(modelsummary)
library(kableExtra)
library(DescTools)
library(data.table)
library(car)
library(broom)
library(gtsummary)
library(sjPlot)
library(sjmisc)
library(sjlabelled)
library(moments)
library(stargazer)
library(nortest)
library(wordcountaddin)
indyVI <- read.csv("IndependenceVI_v1_MMcG.csv", na.strings = c("NA"))

indyVI <- mutate(indyVI,
                 CATI = fifelse(DataCollect == 1, 1, 0),
                 Panel = fifelse(DataCollect == 2, 1, 0),
                 F2F = fifelse(DataCollect == 3, 1, 0),
                 GEFranchise = fifelse(Franchise == 1, 1, 0),
                 ScotFranchise = fifelse(Franchise == 2, 1, 0),
                 BMG = fifelse(Pollster == 1, 1, 0),
                 Deltapoll = fifelse(Pollster == 2, 1, 0),
                 FindOutNow = fifelse(Pollster == 3, 1, 0),
                 Hanbury = fifelse(Pollster == 4, 1, 0),
                 ICM = fifelse(Pollster == 5, 1, 0),
                 Ipsos = fifelse(Pollster == 6, 1, 0),
                 JLPartners = fifelse(Pollster == 7, 1, 0),
                 LAP = fifelse(Pollster == 8, 1, 0),
                 Opinium = fifelse(Pollster == 9, 1, 0),
                 Panelbase = fifelse(Pollster == 10, 1, 0),
                 RandW = fifelse(Pollster == 11, 1, 0),
                 Savanta = fifelse(Pollster == 12, 1, 0),
                 StackData = fifelse(Pollster == 13, 1, 0),
                 Survation = fifelse(Pollster == 14, 1, 0),
                 TNS = fifelse(Pollster == 15, 1, 0),
                 YouGov = fifelse(Pollster == 16, 1, 0))

indyVI <- apply_labels(indyVI,
                       Time = "Days since the 2014 independence referendum",
                       Pollster = "Research agency that conducted fieldwork",
                       Yes = "Proportion of likely voters in the sample who would vote Yes in a referendum held now",
                       No = "Proportion of likely voters in the sample who would vote No in a referendum held now",
                       DK = "Proportion of likely voters in the sample who are undecided on how they would vote in a referendum held now",
                       IndyrefWeight = "Weighted to recalled 2014 independence referendum vote",
                       PastScotElectWeight = "Weighted to recalled constituency vote in the most recent Scottish Parliament election",
                       PastBritElectWeight = "Weighted to recalled vote in the most recent UK Parliament election",
                       DataCollect = "Method of data collection",
                       Franchise = "Scottish election franchise (16+) or UK election franchise (18+)",
                       CATI = "Data collected via telephone interview",
                       Panel = "Data collected via online panel",
                       F2F = "Data collected via face-to-face interview",
                       GEFranchise = "Sample of Scottish adults age 18+",
                       ScotFranchise = "Sample of Scottish adults age 16+",
                       BMG = "Poll conducted by BMG Research",
                       Deltapoll = "Poll conducted by ",
                       FindOutNow = "Poll conducted by FindOutNow",
                       Hanbury = "Poll conducted by Hanbury Strategy",
                       ICM = "Poll conducted by ICM",
                       Ipsos = "Poll conducted by Ipsos",
                       JLPartners = "Poll conducted by JL Partners",
                       LAP = "Poll conducted by Lord Ashcroft",
                       Opinium = "Poll conducted by Opinium",
                       Panelbase = "Poll conducted by Panelbase",
                       RandW = "Poll conducted by Redfield and Wilton",
                       Savanta = "Poll conducted by Savanta ComRes",
                       StackData = "Poll conducted by Stack Data",
                       Survation = "Poll conducted by Survation",
                       TNS = "Poll conducted by TNS",
                       YouGov = "Poll conducted by YouGov")

indyVI <- mutate(indyVI,
                 Pollster = factor(Pollster,
                                   levels = 1:16,
                                   labels = c("BMG Research", "Deltapoll", "FindOutNow", "Hanbury Strategy", "ICM", "Ipsos", "JL Partners", "Lord Ashcroft Polls", "Opinium", "Panelbase", "Redfield and Wilton", "Savanta", "Stack Data", "Survation", "TNS", "YouGov")))

indyVI <- mutate(indyVI,
                 DataCollect = factor(DataCollect,
                                      levels = 1:3,
                                      labels = c("Telephone", "Online Panel", "Face-to-face")))

indyVI <- mutate(indyVI,
                 Franchise = factor(Franchise,
                                    levels = 1:2,
                                    labels = c("18+", "16+")))

options(scipen = 999)
options(tinytex.verbose = TRUE)
```

## TL;DR

* The methodologies of research agencies conducting Scottish independence polling have come under greater-than-normal scrutiny in the past few weeks, as a result of a glut of polls showing support for Scottish independence at a higher level than support for the Union. These polls immediately followed a UK Supreme Court ruling that the Scottish Parliament cannot unilaterally hold a referendum on Scottish independence, and have driven a narrative that this ruling (among other factors) has led to a rise in support for independence.

* In particular, campaigners have made the claim that companies that do not weight their data to reflect the outcome of the 2014 Scottish independence referendum report higher pro-independence voting intention than those that do. Some pro-Union campaigners have characterised this as an unfair bias that produces inaccurate results.

* We aim here to determine whether or not there is a __statistically and substantively significant difference__ in reported pro-independence voting intention between polls that do and do not weight by 2014 vote, by developing a robust multivariate regression model.

* We find that there is a __statistically significant difference in reported pro-independence voting intention__ between polls that do and do not weight by 2014 vote, but that __the effect size of this difference is relatively small - 1.86pts__.

* We further find that whether or not a poll weights to the Scottish vote in the most recent UK Parliament election has a statistically significant relationship with reported pro-independence voting intention, of 1.35pts, as does excluding 16- and 17-year-olds - 1.46pts.

* Whether or not research agency _should_ weight by 2014 vote is beyond the scope of this write-up

## Background

Secessionism in Scotland is a highly sensitive topic. The Scottish National Party's dominance of Scottish politics since 2011 has produced three pro-independence Scottish Parliaments (since 2016, in conjunction with the Scottish Greens), and three pro-independence majorities of Scottish seats in the UK Parliament. It also produced a referendum on Scottish independence in 2014, which was lost by the pro-independence camp by 55% of the vote to 45%.

Consistent pro-independence majorities of seats in a country that voted by majority to remain in the UK has kept secession high up the political agenda without actually resolving the issue. As time has passed and positions have entrenched on both sides, being 'Yes' (pro-independence) or 'No' (pro-Union) has become a political identity, with strong polarisation between the two poles of opinion.

Accordingly, coverage of secessionism and political campaigning for and against it is often received through a partisan prism - online advocates for both sides are particularly prone to react to coverage and commentary by amplifying content that they perceive to benefit their own camp, and by undermining content that is detrimental to their cause. This partisanship often takes the form of conspiracy theory, and even ad hominem attacks.

In this context, opinion polling on Scottish independence has become politicised in the same manner as any other content. Activists and campaigners on both sides are prone to accusations of bias or dodgy methodology towards research agencies the results of whose polls they do not like.

In recent weeks, this contestation over opinion polling has intensified. The UK Supreme Court ruled in November that the Scottish Parliament and Government are not, under the Scotland Act 1998, empowered to hold a referendum on Scottish independence without the UK Government consenting to one. In the aftermath, a series of six polls have found a rise in support for Scottish independence of around 4-5 percentage points. Some polls found larger rises and higher overall levels of support for independence than other polls.

Several of these polls have come under attack over their weighting schemes, in particular because three of the post-UKSC ruling polls do not weight data by vote in the 2014 independence referendum - which some campaigners claim 'inflates' support for independence.

## Aims

The purpose of this model is to assess whether or not weighting a poll by 2014 vote has an impact on the reported level of support for independence in a given poll. It is *not* its purpose to argue that it is right or wrong to do so. There are arguments for (to more accurately reflect the stated preferences of an electorate) and against (false recall and demographic churn since 2014), which I will not litigate here.

Thus far, campaigners claiming that not weighting by 2014 vote has a significant impact on reported pro-independence voting intention have supported this claim with side-by-side comparisons of selected polls which do and do not weight by 2014 vote.

There are obvious flaws with this kind of analysis. Firstly, the selected polls are not necessarily representative of Scottish independence polling as a whole.

Secondly, no attempt is made to test whether such differences are statistically significant or as likely to be a result of statistical noise as they are to be the result of structural differences between polls.

And thirdly, such analysis omits other variables - other weighting factors, recruitment method, data collection method, sample structure, method of likelihood-to-vote calculation - which vary structurally between research agency.

The aim here is to begin to address these defects by:

1. Conducting an analysis of *all* Scottish independence voting intention polls since the 2014 Scottish independence referendum.
2. Carrying out relevant statistical testing to determine whether there is a statistically significant difference between polls based on 2014 vote weighting.
3. Developing a regression model that includes other variables one might expect to influence the outcome of a poll, within the bounds of the information available about these polls.

### Scottish independence polling since 2014

Between October 2014 and December 2022, 204 polls were conducted which asked representative samples of Scottish voters whether Scotland should be an independent country, using the question wording from the 2014 referendum ballot and a Yes/No/'Don't know' answer scale, and which included some form of likely voter modelling.

These polls form the sample for this analysis. _Table 1_ summarises the support of and opposition to Scottish independence found across these polls.

```{r}
T1 <- indyVI %>% 
  select(Yes, No, DK) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{min}"),
              missing = "no")  %>%
  modify_header(stat_0 ~ "**Minimum**")

T2 <- indyVI %>% 
  select(Yes, No, DK) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{max}"),
              missing = "no")  %>%
  modify_header(stat_0 ~ "**Maximum**")

T3 <- indyVI %>% 
  select(Yes, No, DK) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{mean}"),
              missing = "no")  %>%
  modify_header(stat_0 ~ "**Mean**")

T4 <- indyVI %>% 
  select(Yes, No, DK) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{median}"),
              missing = "no")  %>%
  modify_header(stat_0 ~ "**Median**")

T5 <- indyVI %>% 
  select(Yes, No, DK) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{sd}"),
              missing = "no")  %>%
  modify_header(stat_0 ~ "**Standard Deviation**")

tbl_merge(list(T1, T2, T3, T4, T5)) %>%
  modify_header(label = "") %>% 
  modify_footnote(everything() ~ NA_character_) %>%
  modify_spanning_header(everything() ~ NA_character_) %>% 
  as_kable_extra(booktabs = TRUE,
                 linesep = "",
                 caption = "Table 1: Descriptive Statistics (Continuous Variables)") %>% 
  kable_classic(html_font = "Times New Roman") %>% 
  column_spec(column = c(2:6), width = "2cm") %>% 
  footnote(general = "Scottish Independence Voting Intention Polls (October 2014 - December 2022)",
           general_title = "Source: ",
           footnote_as_chunk = TRUE)
```

_Table 2_ summarises the rest of the dataset used in this analysis. Almost 7-in-10 (68%) of polls conducted by 2014 have been by three research agencies - Panelbase, Survation, and YouGov. All three of these agencies weight their data by 2014 vote. The only other agencies to have conducted polling into the double-digits are Savanta and Ipsos. Most, but not all, Savanta polls are weighted using 2014 vote. No Ipsos poll is weighted to 2014 vote.

As a result of the preponderance of polls being conducted by a handful of agencies, which for the most part weight by 2014 vote, 4-in-5 (81%) polls are weighted in this way. Two-in-five (39%) polls not weighted by 2014 vote were conducted by a single agency, Ipsos.

The vast majority (89%) of polls were conducted via an online panel methodology. 19 - including Ipsos' 15 - were conducted by telephone. Just 3 were conducted face-to-face, all by TNS.

```{r}
indyVI %>% 
  select(Pollster, DataCollect, Franchise, IndyrefWeight, PastScotElectWeight, PastBritElectWeight) %>% 
  tbl_summary(type = list(Pollster = "categorical",
                          DataCollect = "categorical",
                          Franchise = "categorical",
                          IndyrefWeight = "dichotomous",
                          PastScotElectWeight = "dichotomous",
                          PastBritElectWeight = "dichotomous"),
              label = list(Pollster = "Research agency that conducted fieldwork",
                           DataCollect = "Method of data collection",
                           Franchise = "Scottish election franchise (16+) or UK election franchise (18+)",
                           IndyrefWeight = "Weighted to 2014 independence referendum vote",
                           PastScotElectWeight = "Weighted to constituency vote in the most recent Scottish Parliament election",
                           PastBritElectWeight = "Weighted to vote in the most recent UK Parliament election"),
              statistic = list(all_categorical() ~ "{n} ({p}%)",
                               all_dichotomous() ~ "{n} ({p}%)"),
              missing = "no")  %>%
  modify_header(stat_0 ~ "**Count (%)**") %>%
  modify_header(label = "") %>% 
  modify_footnote(everything() ~ NA_character_) %>%
  modify_spanning_header(everything() ~ NA_character_) %>% 
  as_kable_extra(booktabs = TRUE,
                 linesep = "",
                 caption = "Descriptive Statistics (Categorical Variables)") %>% 
  kable_classic(html_font = "Times New Roman", full_width = FALSE) %>% 
  footnote(general = "Scottish Independence Voting Intention Polls (October 2014 - December 2022)",
           general_title = "Source: ",
           footnote_as_chunk = TRUE) %>% 
  column_spec(2, bold = FALSE) %>% 
  row_spec(1, bold = TRUE) %>% 
  row_spec(18, bold = TRUE) %>% 
  row_spec(22, bold = TRUE) %>% 
  pack_rows("Past Vote Weights", 25, 27)
```

## Comparisons of 2014 Vote Weighted and Non-Weighted Polls

Our question of interest is whether or not weighting poll data to reflect the outcome of the 2014 independence referendum has a statistically and substantially significant effect on reported pro-independence voting intention in that poll. We can formalise this in order to test it, in the form of the following hypothesis:

_H1_: Scottish independence voting intention polls with data weighted to reflect the outcome of the 2014 Scottish independence referendum will report *lower* pro-independence voting intention than polls that are not so weighted.

So, is there a difference? As we can see in _table 3_, polls that weight data by 2014 have a lower mean pro-independence voting intention (43.9%) compared to those that do not weight by 2014 vote (47%) - a difference of 3.1pts. A smaller gap exists for mean pro-Union voting intention (1.6pts) and undecideds (1.3pts). We see a similar pattern for median voting intention.

```{r}
T6 <- indyVI %>% 
  select(Yes, No, DK, IndyrefWeight) %>% 
  filter(., IndyrefWeight == 0) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{mean}"),
              missing = "no",
              include = c(Yes, No, DK))  %>%
  modify_header(stat_0 ~ "**Mean**")

T7 <- indyVI %>% 
  select(Yes, No, DK, IndyrefWeight) %>% 
  filter(., IndyrefWeight == 0) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{median}"),
              missing = "no",
              include = c(Yes, No, DK))  %>%
  modify_header(stat_0 ~ "**Median**")

T8 <- indyVI %>% 
  select(Yes, No, DK, IndyrefWeight) %>% 
  filter(., IndyrefWeight == 0) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{sd}"),
              missing = "no",
              include = c(Yes, No, DK))  %>%
  modify_header(stat_0 ~ "**Std Dev**")

T9 <- indyVI %>% 
  select(Yes, No, DK, IndyrefWeight) %>% 
  filter(., IndyrefWeight == 1) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{mean}"),
              missing = "no",
              include = c(Yes, No, DK))  %>%
  modify_header(stat_0 ~ "**Mean**")

T10 <- indyVI %>% 
  select(Yes, No, DK, IndyrefWeight) %>% 
  filter(., IndyrefWeight == 1) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{median}"),
              missing = "no",
              include = c(Yes, No, DK))  %>%
  modify_header(stat_0 ~ "**Median**")

T11 <- indyVI %>% 
  select(Yes, No, DK, IndyrefWeight) %>% 
  filter(., IndyrefWeight == 1) %>% 
  tbl_summary(type = list(Yes ~ "continuous",
                          No ~ "continuous",
                          DK ~ "continuous"),
              label = list(Yes ~ "Yes",
                           No ~ "No",
                           DK ~ "Undecided"),
              statistic = list(all_continuous() ~ "{sd}"),
              missing = "no",
              include = c(Yes, No, DK))  %>%
  modify_header(stat_0 ~ "**Std Dev**")

tbl_merge(list(T6, T7, T8, T9, T10, T11)) %>%
  modify_header(label = "") %>% 
  modify_footnote(everything() ~ NA_character_) %>%
  modify_spanning_header(everything() ~ NA_character_) %>% 
  as_kable_extra(booktabs = TRUE,
                 linesep = "",
                 caption = "Voting Intention Descriptive Stats by Weighting") %>% 
  kable_classic(html_font = "Times New Roman") %>% 
  add_header_above(c(" " = 1, "Not Weighted to 2014 Vote" = 3, "Weighted to 2014 Vote" = 3), bold = TRUE) %>% 
  footnote(general = "Scottish Independence Voting Intention Polls (October 2014 - December 2022)",
           general_title = "Source: ",
           footnote_as_chunk = TRUE)
```

However, we can also see from _table 3_ that the standard deviations for mean voting intention in both groups of polls are as large, if not larger, than the differences between their means. A probability density plot of both sets of polls, _chart 1_, demonstrates this significant overlap in pro-independence voting intention found by polls that do and do not weight by 2014 vote. 


```{r}
indyVI %>% mutate(indyVI,
                  IndyrefWeightChart = fifelse(IndyrefWeight == 1, 1, 2)) %>% 
  mutate(indyVI,
         IndyrefWeightChart = factor(IndyrefWeightChart,
                                     levels = 1:2,
                                     labels = c("Weighted by 2014 indyref vote", "Not weighted by 2014 indyref vote"))) %>%
  ggplot(aes(Yes)) + 
  geom_density(aes(fill = IndyrefWeightChart), alpha = 0.5) + 
  theme_classic() +
  labs(title = "Chart 1: Distribution of Yes vote % by 2014 indyref vote weighting",
       x = "Reported Pro-independence Voting Intention %",
       y = "% of Polls",
       caption = "Scottish Independence Voting Intention Polls (October 2014 - December 2022)") +
  scale_fill_manual(values = c("#4daf4a","#1f78b4")) +
  theme(text = element_text(family = "serif"),
        plot.title = element_text(size = 14, colour = "Black", face = "bold"),
        axis.title.x = element_text(size = 12, colour = "Black", face = "bold"),
        axis.title.y = element_text(size = 12, colour = "Black", face = "bold", angle = 0, vjust=0.5),
        axis.text.x = element_text(size = 12, colour = "Black"),
        axis.text.y = element_text(colour = "Black"),
        legend.position = "top",
        legend.title = element_blank())
```


To ensure that the differences in mean pro-independence voting intention are likely to be 'real' - that is, not the result of statistical noise or 'error' - we need to carry out statistical testing. The distribution of Yes voting intention for 2014 vote weighted polls looks close to a 'normal distribution', but the distribution for non-2014 vote weighted polls looks less so. This matters because the kind of test we use to determine whether the difference in mean pro-independence voting intention is likely to be 'real' depends on the normality, or otherwise, of these distributions.

To double-check, we can carry out Shapiro-Wilks tests for normality, which tests whether or not a distribution varies statistically significantly from a 'normal' distribution. In both the case of 2014 weighted polls (_p_ = 0.0696) and non-2014 weighted polls (_p_ = 0.1876) we can assume that the distribution of Yes voting intention does not vary significantly from the normal distribution.

We therefore use a one-tailed (as our hypothesis is directional) t-test to determine whether or not the mean pro-independence voting intentions for the two groups of polls differ statistically significantly - and they *do* (_t_ = 4.386, _df_ = 45.98, _p_ < 0.0001).

So we can say that the mean pro-independence voting intention reported by polls that are weighted to reflect the 2014 Scottish independence referendum result is statistically significantly *lower* those that do not weight in this way, by 3.1 percentage points.

```{r, results = 'hide'}
shap1 <- indyVI %>% select(Yes, IndyrefWeight)

shap2 <- filter(shap1, IndyrefWeight == 0)
shap2 <- shap2 %>% select(Yes)
shap2 <- as.numeric(unlist(shap2))

shap3 <- filter(shap1, IndyrefWeight == 1)
shap3 <- shap3 %>% select(Yes)
shap3 <- as.numeric(unlist(shap3))

shapiro.test(shap2)
shapiro.test(shap3)

t.test(Yes ~ IndyrefWeight, alternative = "greater", data = indyVI)
```

## Regression Modelling

We know that there is a statistically significant difference of a few percentage points between pro-independence voting intention in Scottish polls, depending on whether they are weighted to reflect the outcome of the 2014 Scottish independence referendum, or not.

However, this is not sufficient to say that there is an effect of 2014 vote weighting on reported pro-independence voting intention. In the first instance, these measures are _correlative_, not _causal_. In the second, without accounting for other factors that may affect reported voting intention we cannot know if the association we have found is a result of 2014 vote weighting, some other set of factors that are associated with both 2014 vote weighting and reported pro-independence voting intention, or a mix of the two.

We therefore need to conduct some multivariate modelling. The models presented below use Ordinary Least Squares (OLS), a basic form of regression modelling. It is imperfect, but proves sufficient to reach some conclusions.

I have included the following predictors:

1. Poll is weighted to reflect the result of the 2014 Scottish independence referendum.
2. Poll is weighted to reflect the constituency vote in the _most recent_ Scottish Parliament election.
3. Poll is weighted to reflect the Scottish vote in the _most recent_ UK Parliament election.
4. Poll was conducted via an online panel.
5. Poll was conducted face-to-face.
6. Poll was conducted using the UK General Election franchise, that is adults age 18 and over.

All of these variables are 'dummy' variables. For predictors 4 and 5, their effects are in comparison to polls conducted by telephone. For predictor 6, its effect is in comparison to polls that use the Scottish election franchise - adults age 16 and over.

I have chosen these for two reasons. Firstly, we have good reasons to expect that they might have an effect on reported pro-independence voting intention:

* Predictor 1 - as we have seen, we know that there is an association between weighting to 2014 vote and reported pro-independence voting intention.
* Predictors 2 and 3 - it is generally accepted in political polling that weighting to past vote can affect the outcome of a poll, and various weighting strategies are employed by different research agencies.
* Predictors 4 & 5 - how poll participants are recruited and interviewed can affect the outcome of a poll for various reasons: for example an online panel may be biased in a particular direction if those who sign up to it are skewed in a given political direction, and may include more politically engaged people than the population; face-to-face polling may suffer from social desirability bias, and particpants may be less willing to disclose their true beliefs to a human interviewer than they would in an online poll.
* Predictor 6 - we know that younger voters are more likely to support Scottish independence, so excluding them from polls may lead to lower reported pro-independence voting intention.

Secondly, all of these predictors are relatively easily identifiable from publicly available sources. There are many other aspects of polling methodology that might affect outcomes, but these are either difficult to identify without working on a given poll (e.g. question ordering, online panel quotas) or difficult to quantify (e.g. interviewing style), or both (e.g. panel blend).

Moreover, as most Scottish independence polls are conducted by a handful of research agencies with largely consistent methodologies, it is likely the case that adding more and more predictors of this kind would be unproductive as the predictors we already have may well control for those we do not.

### Models 1 - 4

Beginning with 2014 vote weighting, predictors are gradually added to build regression models 1 - 4 in _table 4_.

_Model 1_, which includes only 2014 vote weighting, shows a statistically significant relationship between 2014 vote weighting and reported pro-independence voting intention. Based on this bivariate model, we would expect a poll that weights by 2014 vote to find a level of pro-independence voting intention 3.06 points lower than a poll that does not.

However, this model has a low _adjusted R^2_ value - it explains just 11.9% of variation in the reported Yes vote. It's not very good at explaining the variation in pro-independence voting intention between polls.

As we add more predictor variables, the _adjusted R^2_ improves incrementally. By _model 4_, it has risen to 21.9% - better, but not great.

2014 vote weight remains statistically significant through all of these models, but by _model 4_ its effect size - the degree to which we expect it to affect reported pro-independence voting intention - has fallen slightly, and we expect that a poll that weights by 2014 vote would report a pro-independence voting intention 2.94 points lower than a poll that does not. 

And it appears that some of our other predictors are also statistically significantly associated with reported pro-independence voting intention. We would expect a poll conducted face-to-face to find pro-independence voting intention 6.69 points lower than one conducted by telephone, and a poll excluding 16- and 17-year-olds to find pro-independence voting intention 1.51pts lower than one that does not.

```{r, results='hide'}
#Model 1 - Yes Vote v. Indyref Weight (controlled for time)

M1 <- indyVI %>%
  lm(Yes ~ IndyrefWeight, data=.)
summary(M1)

#Model 2 - Model 1 + Other Weights

M2 <- indyVI %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight, data=.)
summary(M2)

#Model 3 - Model 2 + Data Collection Dummies (v. online panel)

M3 <- indyVI %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + F2F, data=.)
summary(M3)

#Model 4 - Model 3 + Franchise (v. 16+)

M4 <- indyVI %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + F2F + GEFranchise, data=.)
summary(M4)
```
```{r, results='asis'}
stargazer(M1, M2, M3, M4,
          style = "apsr",
          column.labels = c("Model 1", "Model 2", "Model 3", "Model 4"),
          dep.var.labels = "Yes Voting Intention",
          dep.var.caption = "",
          covariate.labels = c("(Intercept)", "Weighted by 2014 Indyref Vote", "Weighted by Holyrood Constituency Vote", "Weighted by Westminster Vote", "Online Panel Methodology","Face-to-face Methodology", "18+ Sample"),
          intercept.top = TRUE,
          intercept.bottom = FALSE,
          model.numbers = FALSE, 
          keep.stat = c("n", "rsq", "adj.rsq"),
          notes.align = "r",
          title = "Regression Models",
          table.layout = "-dc-at-s-n")
```

So we have a model, albeit an admittedly rather poor model if what we want to do is predict the pro-independence voting intention a given poll will report. This is to be expected, as we have excluded an enormous number of variables that we might expect to affect not just _reported_ voting intention, but _actual_ support for independence in the population - like the state of the economy, evaluations of the Scottish and UK Governments, or voters' identities, values, and other attitudes.

Luckily, that was not our aim. Our aim was to determine whether or not we can say, with confidence, that weighting data to reflect the result of the 2014 Scottish independence referendum makes a meaningful difference to reported pro-independence voting intention. We seem to have demonstrated that it does.

But we now need to check that our model is robust. A number of assumptions underpin OLS, and we need to make sure that our model satisfies those assumptions. We therefore carry out a number of robustness checks.

In statistics parlance, we want our model to be 'BLUE' - Best Linear Unbiased Estimator. In other words, we want our model's predictions for each poll to be linear, to minimise error, and to be unbiased. We also assume that our error terms (a measure of the difference between what our model predicts and what our dataset actually tells us) are normally distributed, that there is no multicollinearity between our predictors (that our predictors do not predict for one another), and that we do not have any data points that are influential outliers (which can skew our model).

I will not be going into the detail of all of the tests conducted to check whether our model satisfies the assumptions underpinning OLS, though the code for doing so is included in the R Markdown version of this document.

```{r, eval=FALSE}
M4 %>%
  resettest(., power=2:3, type='fitted')

M4 %>% 
  bptest(., studentize = FALSE)

shapiro.test(M4$residuals)

vif(M4)

M4 %>% plot(which=5)
```

Having run these tests, we find that there is no multicollinearity between our predictors, and our error terms are normally distributed.

However, our model is incorrectly specified - perhaps because of omitted variable bias, which is to say that there is structure in the unexplained variance between our model's estimated pro-independence voting intention for each poll, and the pro-independence voting intention reported in that poll.

It also suffers from heteroscedasticity - our error terms are not independent of our predictions for each poll, they are related. Furthermore, our model features some autocorrelation - at least some data points are related to previous data points. We will return to these problems, which are fixable.

The fourth problem our model faces is that it features influential outliers. As it turns out, both of these outliers are TNS polls - the only polls in the dataset conducted face-to-face. There is a third TNS outlier which is not infuential.

I chose to remove these from the dataset and rerun the model. No Scottish independence polls are conducted face-to-face anymore, and TNS is no longer around as a pollster of Scottish independence voting intention, so their usefulness in this analysis is potentially limited. Given their detrimental impact on the model, it makes sense to exclude them from the analysis.

### Model 5

With the TNS polls removed, our model - now _model 5_ - still finds a statistically significant relationship between 2014 vote weighting and reported pro-independence voting intention. However, the effect size is smaller - we'd now expect a poll that weights to the 2014 result to report pro-independence voting intention 2.5pts lower than a poll that doesn't.

We would also expect a poll that weights by the Scottish vote in the most recent UK Parliament election to report pro-independence voting intention figures 1.31pts lower than a poll that does not, and one that excludes 16- and 17-year-olds to find figures 1.5pts lower.

```{r, results='hide'}
indyVI2 <- indyVI[-c(22,61,72),]

M5 <- indyVI2 %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + GEFranchise, data=.)
summary(M5)
```
```{r, results='asis'}
stargazer(M5,
          style = "apsr",
          column.labels = c("Model 5"),
          dep.var.labels = "Yes Voting Intention",
          dep.var.caption = "",
          covariate.labels = c("(Intercept)", "Weighted by 2014 Indyref Vote", "Weighted by Holyrood Constituency Vote", "Weighted by Westminster Vote", "Online Panel Methodology", "18+ Sample"),
          intercept.top = TRUE,
          intercept.bottom = FALSE,
          model.numbers = FALSE, 
          keep.stat = c("n", "rsq", "adj.rsq"),
          notes.align = "r",
          title = "Regression Model 5",
          table.layout = "-dc-at-s-n")
```

We now re-run our robustness checks. While we still have some outliers, and some high-leverage data points, none are influential enough to be concerned about - and they certainly do not offer a justification for removing them from the dataset.

However, we continue to have issues with our model specification and heteroscedasticity. At this point, it is worth pointing out that - to an extent - our model deals with time-series data. We typically use OLS regression to deal with cross-sectional data (polls themselves are a classic example - data collected at one point in time, as a snapshot). But our data points, each poll, occur in a linear series over time. That may at least partial account for the unexplained structure in our data.

That we continue to also have an autocorrelation problem suggests that may be the right interpretation. So, the next step is to try to account for that.

```{r, eval=FALSE}
M5 %>%
  resettest()

M5 %>% 
  bptest(., studentize = FALSE)

shapiro.test(M5$residuals)

vif(M5)

M5 %>% plot(which=5)

M5Residuals <- residuals(M5)
acf(M5Residuals, type = "correlation")
dwtest(M5)
```

### Model 6

Typically, we deal with autocorrelation in OLS by introducing a lag variable. There are, of course, other and better methods for modelling time-series data to help us understand why a given variable changes over time. But, again, that is not the aim here. So we'll settle for introducing a lag variable in _model 6_.

Lagged Yes Vote Intention for each poll is equal to the pro-independence voting intention reported in the most recent previous poll. There are, of course, alternative lag variables - for example, the poll that came second-to-most recently, or third-to-most recently. Or, the poll immediately before the given poll but within the same research agency's polling series. For this reason, in addition to _model 6_ we should construct models with alternative lag variables.

Alternative lagged models find largely the same relationships as _model 6_, but are increasingly plagued by autocorrelation the further from the given poll that the lag variable is drawn. Polls reflect other polls around them more than polls further in the past, even within a research agency's own series. The code for these models and their robustness checks is included at the end of the R Markdown version of this document.

_Model 6_ is our conclusive model. It suffers from none of the issues with our previous models, is BLUE, and satisfies all of the assumptions underpinning OLS regression.

We find that three of our predictors have statistically significant relationships with reported pro-independence voting intention. We would expect a poll that weights by 2014 vote to report pro-independence voting intention that is 1.86pts lower than a poll that does not; a poll that weights to the Scottish vote in the most recent UK Parliament election would find figures 1.35pts lower than a poll that does now, and a poll that excludes 16- and 17-year-olds would find figures 1.46pts lower than a poll that does not.

Our lag variable is also statistically significant, but does not require (and should not recieve!) interpretation similar to our other predictors. The _adjusted R^2_ is higher than our other models - _model 6_ explains 31% of variation in reported pro-independence voting intention - but this is entirely down to our lag variable.

```{r, warning=FALSE, results='hide'}
M6 <- indyVI2 %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + GEFranchise + lYes.1, data=.)
summary(M6)
```
```{r, eval = FALSE}
M6 %>%
  resettest()

M6 %>% 
  bptest(., studentize = FALSE)

shapiro.test(M6$residuals)

vif(M6)

M6 %>% plot(which=5)

M6Residuals <- residuals(M6)
acf(M6Residuals, type = "correlation")
dwtest(M6)
```
```{r, results='asis'}
stargazer(M6,
          style = "apsr",
          column.labels = c("Model 6"),
          dep.var.labels = "Yes Voting Intention",
          dep.var.caption = "",
          covariate.labels = c("(Intercept)", "Weighted by 2014 Indyref Vote", "Weighted by Holyrood Constituency Vote", "Weighted by Westminster Vote", "Online Panel Methodology", "18+ Sample", "Lagged Yes Vote Intention"),
          intercept.top = TRUE,
          intercept.bottom = FALSE,
          model.numbers = FALSE, 
          keep.stat = c("n", "rsq", "adj.rsq"),
          notes.align = "r",
          title = "Regression Model 6",
          table.layout = "-dc-at-s-n")
```

## Conclusions

Whether or not a poll weights by 2014 vote has a statistically significant, but quite small association with its reported pro-independence voting intention once we control for other broad methodological choices. Whether this effect size would continue to shrink, or disappear entirely, should we control for more factors is a question of interest.

This does not necessarily mean that it is necessarily wrong for a research agency to weight by 2014 vote, or not - that discussion is beyond the scope of this write-up, but there are arguments both ways. Indeed, it is valuable to have a plurality of methodological approaches to measuring public opinion on such a sensitive topic.

### About the author

Mark McGeoghegan is a doctoral researcher at the University of Glasgow, specialising in the study of secessionist movements, political contention, and political violence. He also has a background as a public opinion researcher, and writes about Scottish politics and the politics of secessionism in several outlets.

```{r, eval = FALSE}
#Model 6 with 2-poll lag variable

LagCheck1 <- indyVI2 %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + GEFranchise + lYes.2, data=.)
summary(LagCheck1)

LagCheck1 %>%
  resettest()

LagCheck1 %>% 
  bptest()

shapiro.test(LagCheck1$residuals)

vif(LagCheck1)

LagCheck1 %>% plot(which=5)

LagCheck1Residuals <- residuals(LagCheck1)
acf(LagCheck1Residuals, type = "correlation")
dwtest(LagCheck1)
```

```{r, eval = FALSE}
#Model 6 with 3-poll lag variable

LagCheck2 <- indyVI2 %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + GEFranchise + lYes.3, data=.)
summary(LagCheck2)

LagCheck2 %>%
  resettest()

LagCheck2 %>% 
  bptest()

shapiro.test(LagCheck2$residuals)

vif(LagCheck2)

LagCheck2 %>% plot(which=5)

LagCheck2Residuals <- residuals(LagCheck2)
acf(LagCheck2Residuals, type = "correlation")
dwtest(LagCheck2)
```

```{r, eval = FALSE}
#Model 6 with within-pollster lag variable

LagCheck3 <- indyVI2 %>%
  lm(Yes ~ IndyrefWeight + PastScotElectWeight + PastBritElectWeight + Panel + GEFranchise + lYes.p, data=.)
summary(LagCheck3)

LagCheck3 %>%
  resettest()

LagCheck3 %>% 
  bptest()

shapiro.test(LagCheck3$residuals)

vif(LagCheck3)

LagCheck3 %>% plot(which=5)

LagCheck3Residuals <- residuals(LagCheck3)
acf(LagCheck3Residuals, type = "correlation")
dwtest(LagCheck3)
```











